<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.9.5">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2025-12-15T18:34:03+05:30</updated><id>http://localhost:4000/feed.xml</id><title type="html">Devaraj’s Blog</title><subtitle>My professional blog and portfolio.</subtitle><entry><title type="html">Welcome to Jekyll!</title><link href="http://localhost:4000/jekyll/update/2025/12/15/welcome-to-jekyll.html" rel="alternate" type="text/html" title="Welcome to Jekyll!" /><published>2025-12-15T17:00:00+05:30</published><updated>2025-12-15T17:00:00+05:30</updated><id>http://localhost:4000/jekyll/update/2025/12/15/welcome-to-jekyll</id><content type="html" xml:base="http://localhost:4000/jekyll/update/2025/12/15/welcome-to-jekyll.html"><![CDATA[<p>You’ll find this post in your <code class="language-plaintext highlighter-rouge">_posts</code> directory. Go ahead and edit it and re-build the site to see your changes. You can rebuild the site in many different ways, but the most common way is to run <code class="language-plaintext highlighter-rouge">jekyll serve</code>, which launches a web server and auto-regenerates your site when a file is updated.</p>

<p>To add new posts, simply add a file in the <code class="language-plaintext highlighter-rouge">_posts</code> directory that follows the convention <code class="language-plaintext highlighter-rouge">YYYY-MM-DD-name-of-post.ext</code> and includes the necessary front matter. Take a look at the source for this post to get an idea about how it works.</p>

<p>Jekyll also offers powerful support for code snippets:</p>

<div class="language-ruby highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">print_hi</span><span class="p">(</span><span class="nb">name</span><span class="p">)</span>
  <span class="nb">puts</span> <span class="s2">"Hi, </span><span class="si">#{</span><span class="nb">name</span><span class="si">}</span><span class="s2">"</span>
<span class="k">end</span>
<span class="n">print_hi</span><span class="p">(</span><span class="s1">'Tom'</span><span class="p">)</span>
<span class="c1">#=&gt; prints 'Hi, Tom' to STDOUT.</span>
</code></pre></div></div>

<p>Check out the <a href="https://jekyllrb.com/docs/home">Jekyll docs</a> for more info on how to get the most out of Jekyll. File all bugs/feature requests at <a href="https://github.com/jekyll/jekyll">Jekyll’s GitHub repo</a>. If you have questions, you can ask them on <a href="https://talk.jekyllrb.com/">Jekyll Talk</a>.</p>]]></content><author><name></name></author><category term="jekyll" /><category term="update" /><summary type="html"><![CDATA[You’ll find this post in your _posts directory. Go ahead and edit it and re-build the site to see your changes. You can rebuild the site in many different ways, but the most common way is to run jekyll serve, which launches a web server and auto-regenerates your site when a file is updated.]]></summary></entry><entry><title type="html">LLM as a Judge: A Practical Human Guide for Engineers</title><link href="http://localhost:4000/ai/llm/engineering/2025/11/26/llm-as-a-judge.html" rel="alternate" type="text/html" title="LLM as a Judge: A Practical Human Guide for Engineers" /><published>2025-11-26T15:30:00+05:30</published><updated>2025-11-26T15:30:00+05:30</updated><id>http://localhost:4000/ai/llm/engineering/2025/11/26/llm-as-a-judge</id><content type="html" xml:base="http://localhost:4000/ai/llm/engineering/2025/11/26/llm-as-a-judge.html"><![CDATA[<p>Over the last few years, most discussions around Large Language Models have focused on how well they generate things — text, code, explanations, even entire product workflows. But in my day-to-day work with AI systems, I’ve noticed something far more interesting:</p>

<p>If the first wave of AI was about “LLMs that answer questions,” the next wave is increasingly about “LLMs that evaluate answers.” In other words, AI is slowly becoming both the student and the examiner.</p>

<h2 id="the-shift-to-evaluation">The Shift to Evaluation</h2>

<p>Why does this matter? As we move from chatbots to agents that take action, trust becomes the bottleneck. We can’t just hope the model is right; we need systems that can check their own work or the work of others. <strong>LLM-as-a-Judge</strong> is the architectural pattern where we use one model to grade the quality, safety, and relevance of another model’s output.</p>

<h3 id="key-use-cases">Key Use Cases</h3>
<ol>
  <li><strong>Regression Testing</strong>: Automatically checking if a new prompt version broke existing functionality.</li>
  <li><strong>Safety Guardrails</strong>: Real-time evaluation of responses before they reach the user.</li>
  <li><strong>Data Labeling</strong>: Scaling the creation of training datasets by using AI to label data with high confidence.</li>
</ol>

<p>The future of engineering with AI isn’t just about prompt engineering; it’s about <strong>evaluation engineering</strong>.</p>

<hr />
<p><em>This post was originally published on <a href="https://www.linkedin.com/pulse/llm-judge-practical-human-guide-engineers-devaraj-durairaj-nzr2c/">LinkedIn</a>.</em></p>]]></content><author><name></name></author><category term="ai" /><category term="llm" /><category term="engineering" /><summary type="html"><![CDATA[Why the next wave of AI is about models that evaluate answers, not just generate them.]]></summary></entry></feed>