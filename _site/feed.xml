<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.9.5">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2025-12-15T18:42:02+05:30</updated><id>http://localhost:4000/feed.xml</id><title type="html">Devaraj’s Blog</title><subtitle>My professional blog and portfolio.</subtitle><entry><title type="html">Welcome to Jekyll!</title><link href="http://localhost:4000/jekyll/update/2025/12/15/welcome-to-jekyll.html" rel="alternate" type="text/html" title="Welcome to Jekyll!" /><published>2025-12-15T17:00:00+05:30</published><updated>2025-12-15T17:00:00+05:30</updated><id>http://localhost:4000/jekyll/update/2025/12/15/welcome-to-jekyll</id><content type="html" xml:base="http://localhost:4000/jekyll/update/2025/12/15/welcome-to-jekyll.html"><![CDATA[<p>You’ll find this post in your <code class="language-plaintext highlighter-rouge">_posts</code> directory. Go ahead and edit it and re-build the site to see your changes. You can rebuild the site in many different ways, but the most common way is to run <code class="language-plaintext highlighter-rouge">jekyll serve</code>, which launches a web server and auto-regenerates your site when a file is updated.</p>

<p>To add new posts, simply add a file in the <code class="language-plaintext highlighter-rouge">_posts</code> directory that follows the convention <code class="language-plaintext highlighter-rouge">YYYY-MM-DD-name-of-post.ext</code> and includes the necessary front matter. Take a look at the source for this post to get an idea about how it works.</p>

<p>Jekyll also offers powerful support for code snippets:</p>

<div class="language-ruby highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">print_hi</span><span class="p">(</span><span class="nb">name</span><span class="p">)</span>
  <span class="nb">puts</span> <span class="s2">"Hi, </span><span class="si">#{</span><span class="nb">name</span><span class="si">}</span><span class="s2">"</span>
<span class="k">end</span>
<span class="n">print_hi</span><span class="p">(</span><span class="s1">'Tom'</span><span class="p">)</span>
<span class="c1">#=&gt; prints 'Hi, Tom' to STDOUT.</span>
</code></pre></div></div>

<p>Check out the <a href="https://jekyllrb.com/docs/home">Jekyll docs</a> for more info on how to get the most out of Jekyll. File all bugs/feature requests at <a href="https://github.com/jekyll/jekyll">Jekyll’s GitHub repo</a>. If you have questions, you can ask them on <a href="https://talk.jekyllrb.com/">Jekyll Talk</a>.</p>]]></content><author><name></name></author><category term="jekyll" /><category term="update" /><summary type="html"><![CDATA[You’ll find this post in your _posts directory. Go ahead and edit it and re-build the site to see your changes. You can rebuild the site in many different ways, but the most common way is to run jekyll serve, which launches a web server and auto-regenerates your site when a file is updated.]]></summary></entry><entry><title type="html">LLM as a Judge: A Practical Human Guide for Engineers</title><link href="http://localhost:4000/ai/llm/engineering/2025/11/26/llm-as-a-judge.html" rel="alternate" type="text/html" title="LLM as a Judge: A Practical Human Guide for Engineers" /><published>2025-11-26T15:30:00+05:30</published><updated>2025-11-26T15:30:00+05:30</updated><id>http://localhost:4000/ai/llm/engineering/2025/11/26/llm-as-a-judge</id><content type="html" xml:base="http://localhost:4000/ai/llm/engineering/2025/11/26/llm-as-a-judge.html"><![CDATA[<p>Over the last few years, most discussions around <strong>Large Language Models</strong> have focused on how well they <em>generate</em> things — text, code, explanations, even entire product workflows. But in my day-to-day work with AI systems, I’ve noticed something far more interesting:</p>

<blockquote>
  <p>If the first wave of AI was about <strong>“LLMs that answer questions,”</strong> the next wave is increasingly about <strong>“LLMs that evaluate answers.”</strong> In other words, AI is slowly becoming both the student and the examiner.</p>
</blockquote>

<h2 id="the-shift-to-evaluation">The Shift to Evaluation</h2>

<p>Why does this matter? As we move from chatbots to agents that take action, <span class="highlight-text">trust becomes the bottleneck</span>. We can’t just hope the model is right; we need systems that can check their own work or the work of others.</p>

<p><strong>LLM-as-a-Judge</strong> is the architectural pattern where we use one model to grade the quality, safety, and relevance of another model’s output.</p>

<h3 id="key-use-cases-bulleted-list">Key Use Cases (Bulleted List)</h3>

<ul>
  <li><strong>Regression Testing</strong>: Automatically checking if a new prompt version broke existing functionality.</li>
  <li><strong>Safety Guardrails</strong>: Real-time evaluation of responses before they reach the user.</li>
  <li><strong>Data Labeling</strong>: Scaling the creation of training datasets by using AI to label data with high confidence.</li>
</ul>

<h3 id="evaluation-criteria-numbered-list">Evaluation Criteria (Numbered List)</h3>

<ol>
  <li><strong>Correctness</strong>: Does the answer match the ground truth?</li>
  <li><strong>Relevance</strong>: Is the answer actually addressing the user’s query?</li>
  <li><strong>Tone</strong>: Is the response polite and professional?</li>
  <li><strong>Safety</strong>: Does the response contain PII or harmful content?</li>
</ol>

<h2 id="code-example-simple-evaluation-prompt">Code Example: Simple Evaluation Prompt</h2>

<p>Here is how you might structure a “Judge” prompt (Indented/Code Block):</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">evaluate_response</span><span class="p">(</span><span class="n">question</span><span class="p">,</span> <span class="n">answer</span><span class="p">):</span>
    <span class="n">system_prompt</span> <span class="o">=</span> <span class="s">"""
    You are an expert evaluator. 
    Grade the following answer on a scale of 1-5 
    based on helpfulness and accuracy.
    """</span>
    
    <span class="c1"># ... call LLM API ...
</span>    <span class="k">return</span> <span class="n">score</span>
</code></pre></div></div>

<p>The future of engineering with AI isn’t just about prompt engineering; it’s about <strong>evaluation engineering</strong>.</p>

<hr />
<p><em>This post was originally published on <a href="https://www.linkedin.com/pulse/llm-judge-practical-human-guide-engineers-devaraj-durairaj-nzr2c/">LinkedIn</a>.</em></p>]]></content><author><name></name></author><category term="ai" /><category term="llm" /><category term="engineering" /><summary type="html"><![CDATA[Why the next wave of AI is about models that evaluate answers, not just generate them.]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:4000/assets/images/llm_judge_thumb.png" /><media:content medium="image" url="http://localhost:4000/assets/images/llm_judge_thumb.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry></feed>